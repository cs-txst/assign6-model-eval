{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Model Evaluation and Model Selection\n",
    "\n",
    "### Objective: In this assignment, you will gain hands-on experience in evaluating the performance of machine learning models and selecting the best features for your model. The assignment will focus on the following concepts:\n",
    "\n",
    "- Accuracy evaluation using cross-validation\n",
    "- Confidence intervals for the accuracy or the error rate\n",
    "- Hyperparameter tuning using grid search\n",
    "- Evaluation metrics such as Precision, Recall, and F1-Score, ROC-AUC\n",
    "- Feature selection methods: Filter methods, Embedded methods, and Wrapper methods\n",
    "- Feature extraction methods, such as Principal Component Analysis (PCA)\n",
    "\n",
    "### Dataset:\n",
    "\n",
    "In this assignment we will use the \"Bank Marketing\" dataset. This dataset is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict whether the client will subscribe to a term deposit (yes/no). \n",
    "\n",
    "The dataset contains 20 input features, such as age, job, marital status, education, and others. The target variable is imbalanced, with the majority of the clients not subscribing to the term deposit.\n",
    "\n",
    "You can find the Bank Marketing dataset on the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "\n",
    "For your convenience, the dataset has been dowloaded and can be found in the Data folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Python code to complete each of the tasks below.\n",
    "\n",
    "### 1. Load the dataset into a Pandas dataframe and show the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess the data\n",
    "\n",
    "The dataset contains a combination of numberic and categorical features. The majority of machine learning algorithms work with numeric features. For that reason, we need to convert all our features to numeric by introducing dummy variables using one-hot encoding. We will also normalize the numeric featues to a mean of zero and std of one as most ML algorithms work best with normalized features.\n",
    "\n",
    "(The solution to this step is given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocess categorical features\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "numeric_features = [col for col in data.columns if col not in categorical_features + ['y']]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "# Split into features and targets\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Preprocess the features\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get the column names for the one-hot encoded features\n",
    "onehot_columns = preprocessor.named_transformers_['cat'].get_feature_names_out(input_features=categorical_features)\n",
    "\n",
    "# Combine the numeric and one-hot encoded feature names\n",
    "all_feature_names = numeric_features + list(onehot_columns)\n",
    "\n",
    "# Convert the transformed matrix X back into a DataFrame with the feature names. Pandas provides functions for explorarory data analysis.\n",
    "X = pd.DataFrame(X, columns=all_feature_names)\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform and Exploratory Data Analysis\n",
    "\n",
    "1. Display a histogram of each feature so we can see the distribution of their values.\n",
    "2. Use Seaborn to display a barplot of the correlation of each feature with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are your takeways from the exploratory data analysis?**\n",
    "\n",
    "(Edit this cell and add your answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split the data into a stratified 80/20 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Apply feature selection\n",
    "\n",
    "Use the following feature selection methods:\n",
    "1. Filter: Variance Threshold with a threshold of 0.1\n",
    "2. Embedded: Use the LASSO L1 penalty in the LogisticRegressionCV and keep the features with non-zero coefficients\n",
    "3. Wrapper: Use Recursive Feature Elimination (RFECV) with Logistic Regression as the estimator.\n",
    "4. Feature Extraction: Use PCA to extract the top 20 components\n",
    "\n",
    "For the first three feature selection methods, print out the names of the features that were selected.\n",
    "\n",
    "**Note:** Since this is an imbalanced dataset using the default scoring criterion, which is classification Accuracy, will not yield good results. For that reason, you should use the F1-Score (`scoring='f1'`) whenever you fit a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fine Tune a Classification Algorithm\n",
    "\n",
    "We will use the `GradientBoostingClassifier` which is know to be one of the most powefull ensemble algorithms. Some of the hyperparameters that can be tuned when training a GradientBoostingClassifier are:\n",
    "- Number of estimators (trees): try 100, 200, 300\n",
    "- Learning rate: try 0.01, 0.1\n",
    "- Max (tree) depth: try 3, 4\n",
    "\n",
    "Use `GridSearchCV` to train your classifier for the different hyperparameter values. Remember to use F1-score as your scoring criterion.\n",
    "\n",
    "Tune your model on the features selected by each one of the methods above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluate your tuned models on the test data\n",
    "\n",
    "For each one of the tuned models, print out the following metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- ROC-AUC\n",
    "\n",
    "For the model that produces the best f1-score, print out the confusion matrix and classification report using the skearn `classification_report` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Discuss your results\n",
    "\n",
    "**What are your main takeaways from this assignment?**\n",
    "\n",
    "(Edit this cell and add your answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4347",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
